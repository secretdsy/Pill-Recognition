{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import multiprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'빨강': 0,\n",
       " '주황': 1,\n",
       " '노랑': 2,\n",
       " '연두': 3,\n",
       " '초록': 4,\n",
       " '청록': 5,\n",
       " '파랑': 6,\n",
       " '남색': 7,\n",
       " '보라': 8,\n",
       " '분홍': 9,\n",
       " '자주': 10,\n",
       " '갈색': 11,\n",
       " '회색': 12,\n",
       " '검정': 13,\n",
       " '하양': 14,\n",
       " '투명': 15}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_label = {'삼각형': 0, '사각형': 1, '오각형': 2, '육각형': 3, '팔각형': 4, \n",
    "               '원형': 5, '반원형': 6, '타원형': 7, '장방형': 8, '마름모형': 9, '기타': 10}\n",
    "shape_label\n",
    "\n",
    "color_label = {'빨강': 0, '주황': 1, '노랑': 2, '연두': 3, '초록': 4, \n",
    "               '청록': 5, '파랑': 6, '남색': 7, '보라': 8, '분홍': 9,\n",
    "               '자주': 10, '갈색': 11, '회색': 12, '검정': 13, '하양': 14, '투명': 15}\n",
    "color_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/mask_front'\n",
    "LABEL_PATH = '../label'\n",
    "SAVE_PATH = '../save_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'img_size': (224, 224),\n",
    "    'input_shape': (224, 224, 3),\n",
    "#     'nb_train_samples': len(X_train),\n",
    "#     'nb_validation_samples': len(X_val),\n",
    "#     'img_size': (299, 299),\n",
    "#     'input_shape': (299, 299, 3),\n",
    "    'batch_size': 24,\n",
    "    'epochs': 10,\n",
    "    'nb_workers': multiprocessing.cpu_count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일이 이미 있을 때\n",
    "dataset = pd.read_csv(os.path.join(LABEL_PATH,'shape.csv'))\n",
    "dataset['shape'] = dataset['shape'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16767, 2)\n",
      "(4192, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = dataset[['No', 'shape']]\n",
    "its = np.arange(dataset.shape[0])\n",
    "train_idx, val_idx = train_test_split(its, train_size = 0.8, random_state=42)\n",
    "\n",
    "X_train = dataset.iloc[train_idx, :]\n",
    "X_val = dataset.iloc[val_idx, :]\n",
    "\n",
    "params.update({\n",
    "    'nb_train_samples': len(X_train),\n",
    "    'nb_validation_samples': len(X_val)\n",
    "})\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0 :\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else :\n",
    "        return num_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k\n",
    "from functools import partial\n",
    "top_2 = partial(keras.metrics.top_k_categorical_accuracy, k=2)\n",
    "top_2.__name__ = 'top_2'\n",
    "\n",
    "top_3 = partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3.__name__ = 'top_3'\n",
    "\n",
    "top_5 = keras.metrics.top_k_categorical_accuracy\n",
    "top_5.__name__ = 'top_5'\n",
    "\n",
    "top_10 = partial(keras.metrics.top_k_categorical_accuracy, k=10)\n",
    "top_10.__name__ = 'top_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16768 validated image filenames belonging to 11 classes.\n",
      "Found 4191 validated image filenames belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='shape',\n",
    "                                            subset='training',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'])\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='shape',\n",
    "                                            subset='validation',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'],\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20959 validated image filenames.\n",
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "874/874 [==============================] - 77s 88ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(os.path.join(LABEL_PATH,'shape_color_prediction.csv'))\n",
    "dataset_test = dataset_test[['No']]\n",
    "\n",
    "from keras.models import load_model\n",
    "params.update({\n",
    "    'nb_test_samples': len(dataset_test)\n",
    "})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=dataset_test,\n",
    "    directory=DATA_PATH,\n",
    "    x_col='No',\n",
    "    y_col=None,\n",
    "    target_size=params['img_size'],\n",
    "    class_mode=None,\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False)\n",
    "\n",
    "dependencies = {\n",
    "    'top_2': top_2,\n",
    "    'top_3': top_3,\n",
    "    'top_5': top_5\n",
    "}\n",
    "model = keras.models.load_model(os.path.join(SAVE_PATH, 'VGG16_shape_ep004_vloss-0.1574_vacc-0.9759.h5'), custom_objects=dependencies)\n",
    "\n",
    "prediction = model.predict_generator(generator = test_generator,\n",
    "                                     steps = get_steps(params['nb_test_samples'], params['batch_size']),\n",
    "                                     verbose=1,\n",
    "                                     workers=params['nb_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# submission = pd.read_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'))\n",
    "# submission['shape_prediction'] = predictions\n",
    "# submission.to_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 지우지말자 #################\n",
    "\n",
    "def top_k_label(K):\n",
    "    top_list = []\n",
    "    predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    class_probs = prediction\n",
    "    for i, l in enumerate(predictions): # idx, label\n",
    "        class_prob = class_probs[i]\n",
    "        top_values = (-class_prob).argsort()[:K].tolist() # k 개까지 높은 확률 인덱스 저장\n",
    "        top_list.append(top_values)\n",
    "    \n",
    "    top_arr = np.zeros((len(top_list), K))\n",
    "    \n",
    "    for i in range(len(top_list)): # key - values 값 바꾸기\n",
    "        for j in range(K):\n",
    "            tmp = top_list[i][j]\n",
    "            top_arr[i][j] = labels[tmp]\n",
    "    \n",
    "    label_list = top_arr.tolist()\n",
    "    return label_list\n",
    "\n",
    "\n",
    "# top_k_label(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = top_k_label(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### color ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일이 이미 있을 때\n",
    "dataset = pd.read_csv(os.path.join(LABEL_PATH,'color.csv'))\n",
    "dataset['color_front'] = dataset['color_front'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16767, 2)\n",
      "(4192, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = dataset[['No', 'color_front']]\n",
    "its = np.arange(dataset.shape[0])\n",
    "train_idx, val_idx = train_test_split(its, train_size = 0.8, random_state=42)\n",
    "\n",
    "X_train = dataset.iloc[train_idx, :]\n",
    "X_val = dataset.iloc[val_idx, :]\n",
    "\n",
    "params.update({\n",
    "    'nb_train_samples': len(X_train),\n",
    "    'nb_validation_samples': len(X_val)\n",
    "})\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16768 validated image filenames belonging to 16 classes.\n",
      "Found 4191 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='color_front',\n",
    "                                            subset='training',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'])\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='color_front',\n",
    "                                            subset='validation',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'],\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20959 validated image filenames.\n",
      "874/874 [==============================] - 75s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(os.path.join(LABEL_PATH,'shape_color_prediction.csv'))\n",
    "dataset_test = dataset_test[['No']]\n",
    "\n",
    "from keras.models import load_model\n",
    "params.update({\n",
    "    'nb_test_samples': len(dataset_test)\n",
    "})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=dataset_test,\n",
    "    directory=DATA_PATH,\n",
    "    x_col='No',\n",
    "    y_col=None,\n",
    "    target_size=params['img_size'],\n",
    "    class_mode=None,\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False)\n",
    "\n",
    "dependencies = {\n",
    "    'top_2': top_2,\n",
    "    'top_3': top_3,\n",
    "    'top_5': top_5\n",
    "}\n",
    "\n",
    "model = keras.models.load_model(os.path.join(SAVE_PATH, 'VGG16_color_ep007_vloss-0.4171_vacc-0.9003.h5'), custom_objects=dependencies)\n",
    "\n",
    "prediction = model.predict_generator(generator = test_generator,\n",
    "                                     steps = get_steps(params['nb_test_samples'], params['batch_size']),\n",
    "                                     verbose=1,\n",
    "                                     workers=params['nb_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# submission = pd.read_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'))\n",
    "# submission['color_prediction'] = predictions\n",
    "# submission.to_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 지우지말자 #################\n",
    "\n",
    "def top_k_label(K):\n",
    "    top_list = []\n",
    "    predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    class_probs = prediction\n",
    "    for i, l in enumerate(predictions): # idx, label\n",
    "        class_prob = class_probs[i]\n",
    "        top_values = (-class_prob).argsort()[:K].tolist() # k 개까지 높은 확률 인덱스 저장\n",
    "        top_list.append(top_values)\n",
    "    \n",
    "    top_arr = np.zeros((len(top_list), K))\n",
    "    \n",
    "    for i in range(len(top_list)): # key - values 값 바꾸기\n",
    "        for j in range(K):\n",
    "            tmp = top_list[i][j]\n",
    "            top_arr[i][j] = labels[tmp]\n",
    "    \n",
    "    label_list = top_arr.tolist()\n",
    "    return label_list\n",
    "\n",
    "\n",
    "# top_k_label(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = top_k_label(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_1: 0.8979436041795887\n",
      "top_2: 0.9770981439954196\n",
      "top_3: 0.9902189989980438\n",
      "shape_top_2, color_top_3: 0.9877379645975476\n",
      "shape_top_3, color_top_2: 0.9795791783959158\n"
     ]
    }
   ],
   "source": [
    "# top-k 성능비교\n",
    "\n",
    "top1 = 0\n",
    "top2 = 0\n",
    "top3 = 0\n",
    "s2_c3 = 0\n",
    "s3_c2 = 0\n",
    "df = pd.read_csv(os.path.join(LABEL_PATH,'shape_color_prediction.csv'))\n",
    "for i in range(len(df)):\n",
    "    if df['shape'][i] in shape_list[i][0:1] and df['color_front'][i] in color_list[i][0:1]:\n",
    "        top1 += 1\n",
    "    if df['shape'][i] in shape_list[i][0:2] and df['color_front'][i] in color_list[i][0:2]:\n",
    "        top2 += 1\n",
    "    if df['shape'][i] in shape_list[i][0:3] and df['color_front'][i] in color_list[i][0:3]:\n",
    "        top3 += 1\n",
    "    if df['shape'][i] in shape_list[i][0:2] and df['color_front'][i] in color_list[i][0:3]:\n",
    "        s2_c3 += 1\n",
    "    if df['shape'][i] in shape_list[i][0:3] and df['color_front'][i] in color_list[i][0:2]:\n",
    "        s3_c2 += 1\n",
    "        \n",
    "print('top_1:', top1/len(df))\n",
    "print('top_2:', top2/len(df))\n",
    "print('top_3:', top3/len(df))\n",
    "print('shape_top_2, color_top_3:', s2_c3/len(df))\n",
    "print('shape_top_3, color_top_2:', s3_c2/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
