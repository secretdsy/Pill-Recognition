{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import multiprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'빨강': 0,\n",
       " '주황': 1,\n",
       " '노랑': 2,\n",
       " '연두': 3,\n",
       " '초록': 4,\n",
       " '청록': 5,\n",
       " '파랑': 6,\n",
       " '남색': 7,\n",
       " '보라': 8,\n",
       " '분홍': 9,\n",
       " '자주': 10,\n",
       " '갈색': 11,\n",
       " '회색': 12,\n",
       " '검정': 13,\n",
       " '하양': 14,\n",
       " '투명': 15}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_label = {'빨강': 0, '주황': 1, '노랑': 2, '연두': 3, '초록': 4, \n",
    "               '청록': 5, '파랑': 6, '남색': 7, '보라': 8, '분홍': 9,\n",
    "               '자주': 10, '갈색': 11, '회색': 12, '검정': 13, '하양': 14, '투명': 15}\n",
    "color_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/mask_front'\n",
    "LABEL_PATH = '../label'\n",
    "SAVE_PATH = '../save_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xls = pd.read_excel(os.path.join(LABEL_PATH, 'label_color.xls'))\n",
    "# df = pd.DataFrame(xls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['color_front'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # csv 파일 처음 만들 때\n",
    "# img_list = os.listdir(DATA_PATH)\n",
    "# img_list = [e.split('.')[0] for e in img_list]\n",
    "\n",
    "# xls = pd.read_excel(os.path.join(LABEL_PATH, 'label_color.xls'))\n",
    "# df = pd.DataFrame(xls)\n",
    "# df2 = df[df.columns[-1]].map(color_label)\n",
    "# df2 = pd.DataFrame(df2)\n",
    "# df['color_front'] = df2['color_front']\n",
    "# df2 = df[df['No'].isin(img_list)]\n",
    "# df2 = df2.drop_duplicates(['No'], keep='first')\n",
    "# df2 = df2.reset_index()\n",
    "# for i in range(len(df2)):\n",
    "#     df2['No'][i] = str(df2['No'][i]) + '.jpg'\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)\n",
    "\n",
    "# # csv 파일로 만들기\n",
    "# df2.to_csv(os.path.join(LABEL_PATH,'color.csv'), mode='w')\n",
    "# dataset = df2\n",
    "# dataset['color_front'] = dataset['color_front'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일이 이미 있을 때\n",
    "dataset = pd.read_csv(os.path.join(LABEL_PATH,'color.csv'))\n",
    "dataset['color_front'] = dataset['color_front'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16767, 2)\n",
      "(4192, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = dataset[['No', 'color_front']]\n",
    "its = np.arange(dataset.shape[0])\n",
    "train_idx, val_idx = train_test_split(its, train_size = 0.8, random_state=42)\n",
    "\n",
    "X_train = dataset.iloc[train_idx, :]\n",
    "X_val = dataset.iloc[val_idx, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'img_size': (224, 224),\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'nb_train_samples': len(X_train),\n",
    "    'nb_validation_samples': len(X_val),\n",
    "#     'img_size': (299, 299),\n",
    "#     'input_shape': (299, 299, 3),\n",
    "    'batch_size': 24,\n",
    "    'epochs': 10,\n",
    "    'nb_workers': multiprocessing.cpu_count()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0 :\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else :\n",
    "        return num_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16768 validated image filenames belonging to 16 classes.\n",
      "Found 4191 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='color_front',\n",
    "                                            subset='training',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'])\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=DATA_PATH,\n",
    "                                            x_col='No',\n",
    "                                            y_col='color_front',\n",
    "                                            subset='validation',\n",
    "                                            class_mode='categorical',\n",
    "                                            target_size=params['img_size'],\n",
    "                                            batch_size=params['batch_size'],\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k\n",
    "from functools import partial\n",
    "top_2 = partial(keras.metrics.top_k_categorical_accuracy, k=2)\n",
    "top_2.__name__ = 'top_2'\n",
    "\n",
    "top_3 = partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3.__name__ = 'top_3'\n",
    "\n",
    "top_5 = keras.metrics.top_k_categorical_accuracy\n",
    "top_5.__name__ = 'top_5'\n",
    "\n",
    "top_10 = partial(keras.metrics.top_k_categorical_accuracy, k=10)\n",
    "top_10.__name__ = 'top_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 121,690,960\n",
      "Trainable params: 121,690,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\secre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "699/699 [==============================] - 212s 303ms/step - loss: 0.7224 - acc: 0.7841 - top_2: 0.8909 - top_3: 0.9319 - val_loss: 0.4551 - val_acc: 0.8621 - val_top_2: 0.9532 - val_top_3: 0.9780\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86209, saving model to ../save_model\\VGG16_color_ep001_vloss-0.4551_vacc-0.8621.h5\n",
      "Epoch 2/10\n",
      "699/699 [==============================] - 202s 289ms/step - loss: 0.3918 - acc: 0.8821 - top_2: 0.9654 - top_3: 0.9839 - val_loss: 0.4095 - val_acc: 0.8819 - val_top_2: 0.9623 - val_top_3: 0.9804\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86209 to 0.88189, saving model to ../save_model\\VGG16_color_ep002_vloss-0.4095_vacc-0.8819.h5\n",
      "Epoch 3/10\n",
      "699/699 [==============================] - 202s 289ms/step - loss: 0.3517 - acc: 0.8938 - top_2: 0.9709 - top_3: 0.9869 - val_loss: 0.3951 - val_acc: 0.8833 - val_top_2: 0.9630 - val_top_3: 0.9819\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88189 to 0.88332, saving model to ../save_model\\VGG16_color_ep003_vloss-0.3951_vacc-0.8833.h5\n",
      "Epoch 4/10\n",
      "699/699 [==============================] - 205s 294ms/step - loss: 0.3214 - acc: 0.9047 - top_2: 0.9761 - top_3: 0.9899 - val_loss: 0.3901 - val_acc: 0.8926 - val_top_2: 0.9702 - val_top_3: 0.9843\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88332 to 0.89263, saving model to ../save_model\\VGG16_color_ep004_vloss-0.3901_vacc-0.8926.h5\n",
      "Epoch 5/10\n",
      "699/699 [==============================] - 202s 290ms/step - loss: 0.3094 - acc: 0.9066 - top_2: 0.9780 - top_3: 0.9903 - val_loss: 0.4086 - val_acc: 0.8743 - val_top_2: 0.9580 - val_top_3: 0.9778\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89263\n",
      "Epoch 6/10\n",
      "699/699 [==============================] - 201s 288ms/step - loss: 0.3073 - acc: 0.9071 - top_2: 0.9762 - top_3: 0.9899 - val_loss: 0.5167 - val_acc: 0.8745 - val_top_2: 0.9618 - val_top_3: 0.9819\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89263\n",
      "Epoch 7/10\n",
      "699/699 [==============================] - 201s 287ms/step - loss: 0.3056 - acc: 0.9114 - top_2: 0.9773 - top_3: 0.9897 - val_loss: 0.4171 - val_acc: 0.9003 - val_top_2: 0.9726 - val_top_3: 0.9876\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89263 to 0.90026, saving model to ../save_model\\VGG16_color_ep007_vloss-0.4171_vacc-0.9003.h5\n",
      "Epoch 8/10\n",
      "699/699 [==============================] - 201s 287ms/step - loss: 0.3078 - acc: 0.9097 - top_2: 0.9781 - top_3: 0.9908 - val_loss: 0.3711 - val_acc: 0.8924 - val_top_2: 0.9702 - val_top_3: 0.9857\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90026\n",
      "Epoch 9/10\n",
      "699/699 [==============================] - 200s 287ms/step - loss: 0.3135 - acc: 0.9102 - top_2: 0.9773 - top_3: 0.9903 - val_loss: 0.4098 - val_acc: 0.8883 - val_top_2: 0.9644 - val_top_3: 0.9838\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90026\n",
      "Epoch 10/10\n",
      "699/699 [==============================] - 200s 286ms/step - loss: 0.3171 - acc: 0.9090 - top_2: 0.9786 - top_3: 0.9905 - val_loss: 0.4828 - val_acc: 0.8938 - val_top_2: 0.9699 - val_top_3: 0.9857\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90026\n"
     ]
    }
   ],
   "source": [
    "######################## VGG16 #########################\n",
    "from keras.applications import VGG16\n",
    "cnn_model = VGG16(include_top=False, weights='imagenet', input_shape=params['input_shape'])\n",
    "cnn_model.trainable = True\n",
    "model = Sequential()\n",
    "model.add(cnn_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='softmax', kernel_initializer='he_normal'))\n",
    "model.summary()\n",
    "filepath = os.path.join(SAVE_PATH, 'VGG16_color_ep{epoch:03d}_vloss-{val_loss:.4f}_vacc-{val_acc:.4f}.h5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "# earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc', top_2, top_3])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = get_steps(params['nb_train_samples'], params['batch_size']),\n",
    "                              epochs=params['epochs'],\n",
    "                              validation_data=valid_generator, \n",
    "                              validation_steps = get_steps(params['nb_validation_samples'], params['batch_size']),\n",
    "                              callbacks=[checkpoint],\n",
    "                              workers=params['nb_workers'])\n",
    "\n",
    "# from keras.models import load_model\n",
    "# model.save(os.path.join(SAVE_PATH, 'VGG16.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20959 validated image filenames.\n",
      "874/874 [==============================] - 75s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(os.path.join(LABEL_PATH,'shape_color_prediction.csv'))\n",
    "dataset_test = dataset_test[['No']]\n",
    "\n",
    "from keras.models import load_model\n",
    "params.update({\n",
    "    'nb_test_samples': len(dataset_test)\n",
    "})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=dataset_test,\n",
    "    directory=DATA_PATH,\n",
    "    x_col='No',\n",
    "    y_col=None,\n",
    "    target_size=params['img_size'],\n",
    "    class_mode=None,\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False)\n",
    "\n",
    "dependencies = {\n",
    "    'top_2': top_2,\n",
    "    'top_3': top_3,\n",
    "    'top_5': top_5\n",
    "}\n",
    "\n",
    "model = keras.models.load_model(os.path.join(SAVE_PATH, 'VGG16_color_ep007_vloss-0.4171_vacc-0.9003.h5'), custom_objects=dependencies)\n",
    "\n",
    "prediction = model.predict_generator(generator = test_generator,\n",
    "                                     steps = get_steps(params['nb_test_samples'], params['batch_size']),\n",
    "                                     verbose=1,\n",
    "                                     workers=params['nb_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v, k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "submission = pd.read_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'))\n",
    "submission['color_top1'] = predictions\n",
    "submission.to_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_label(K):\n",
    "    top_list = []\n",
    "    predicted_class_indices=np.argmax(prediction, axis=1)\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    class_probs = prediction\n",
    "    for i, l in enumerate(predictions): # idx, label\n",
    "        class_prob = class_probs[i]\n",
    "        top_values = (-class_prob).argsort()[:K].tolist() # k 개까지 높은 확률 인덱스 저장\n",
    "        top_list.append(top_values)\n",
    "        \n",
    "    top_arr = np.zeros((len(top_list), K))\n",
    "    \n",
    "    for i in range(len(top_list)): # key - values 값 바꾸기\n",
    "        for j in range(K):\n",
    "            tmp = top_list[i][j]\n",
    "            top_arr[i][j] = labels[tmp]\n",
    "    \n",
    "    label_list = top_arr.tolist()\n",
    "    return label_list\n",
    "\n",
    "\n",
    "# top_k_label(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>No</th>\n",
       "      <th>color_front</th>\n",
       "      <th>color_top1</th>\n",
       "      <th>color_top3</th>\n",
       "      <th>shape</th>\n",
       "      <th>shape_top1</th>\n",
       "      <th>shape_top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197400571.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[2.0, 1.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5.0, 10.0, 7.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198803039.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>[11.0, 0.0, 1.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[8.0, 7.0, 10.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200703756.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[9.0, 11.0, 1.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5.0, 10.0, 8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>199703153.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>[14.0, 12.0, 2.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[8.0, 10.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>200004062.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>[14.0, 12.0, 2.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[5.0, 10.0, 8.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index             No  color_front  color_top1  \\\n",
       "0           0      0  197400571.jpg            2           2   \n",
       "1           1      1  198803039.jpg           11          11   \n",
       "2           2      2  200703756.jpg            9           9   \n",
       "3           3      3  199703153.jpg           14          14   \n",
       "4           4      4  200004062.jpg           14          14   \n",
       "\n",
       "          color_top3  shape  shape_top1        shape_top3  \n",
       "0    [2.0, 1.0, 3.0]      5           5  [5.0, 10.0, 7.0]  \n",
       "1   [11.0, 0.0, 1.0]      8           8  [8.0, 7.0, 10.0]  \n",
       "2   [9.0, 11.0, 1.0]      5           5  [5.0, 10.0, 8.0]  \n",
       "3  [14.0, 12.0, 2.0]      8           8  [8.0, 10.0, 4.0]  \n",
       "4  [14.0, 12.0, 2.0]      5           5  [5.0, 10.0, 8.0]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top-k csv파일에 저장하기\n",
    "\n",
    "df = pd.read_csv(os.path.join(LABEL_PATH,'shape_color_prediction.csv'))\n",
    "df['color_top3'] = top_k_label(3)\n",
    "df.to_csv(os.path.join(LABEL_PATH, 'shape_color_prediction.csv'), index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
