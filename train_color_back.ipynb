{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import pdb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import layers, models\n",
    "from keras.applications import VGG16\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'갈색': 11,\n",
       " '검정': 13,\n",
       " '남색': 7,\n",
       " '노랑': 2,\n",
       " '보라': 8,\n",
       " '분홍': 9,\n",
       " '빨강': 0,\n",
       " '연두': 3,\n",
       " '자주': 10,\n",
       " '주황': 1,\n",
       " '청록': 5,\n",
       " '초록': 4,\n",
       " '투명': 15,\n",
       " '파랑': 6,\n",
       " '하양': 14,\n",
       " '회색': 12}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_label = {'빨강': 0, '주황': 1, '노랑': 2, '연두': 3, '초록': 4, \n",
    "               '청록': 5, '파랑': 6, '남색': 7, '보라': 8, '분홍': 9,\n",
    "               '자주': 10,'갈색': 11, '회색': 12, '검정': 13, '하양': 14, '투명': 15}\n",
    "#color_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "label_path = './label/label_color_back.xls'\n",
    "xls = pd.read_excel(label_path)\n",
    "df1 = pd.DataFrame(xls)\n",
    "#print(df1)\n",
    "\n",
    "df2 = df1[df1.columns[-1]].map(color_label)\n",
    "df2 = pd.DataFrame(df2)\n",
    "df1['color_back'] = df2['color_back']\n",
    "#print(df1)\n",
    "\n",
    "# cvs 파일로 만들기\n",
    "\n",
    "type(df1)\n",
    "df1.to_csv(\"./label/color_back.csv\", mode='w')\n",
    "\"\"\"\n",
    "\n",
    "dataset = pd.read_csv(\"./label/color_back.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image.py:2059: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.df[x_col] = self.df[x_col].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2637 images belonging to 17 classes.\n",
      "Found 840 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=\"./mask/\",\n",
    "                                            x_col=\"No\",\n",
    "                                            y_col=\"color_back\",\n",
    "                                            has_ext=False,\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32)\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=dataset,\n",
    "                                            directory=\"./mask/\",\n",
    "                                            x_col=\"No\",\n",
    "                                            y_col=\"color_back\",\n",
    "                                            has_ext=False,\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "pre_trained_vgg.trainable = True\n",
    "pre_trained_vgg.summary()\n",
    " \n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(pre_trained_vgg)\n",
    "additional_model.add(layers.Flatten())\n",
    "#additional_model.add(layers.Dense(4096, activation='relu'))\n",
    "#additional_model.add(layers.Dense(2048, activation='relu'))\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(17, activation='softmax'))\n",
    " \n",
    " \n",
    "additional_model.summary()\n",
    " \n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath='pretrained_VGG_weight.hdf5', \n",
    "            monitor='loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)\n",
    " \n",
    "additional_model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
    " \n",
    " \n",
    "history = additional_model.fit_generator(train_generator, \n",
    "            steps_per_epoch=math.ceil(train_generator.n / train_generator.batch_size), \n",
    "            epochs=10, \n",
    "            validation_data=valid_generator, \n",
    "            validation_steps=math.ceil(valid_generator.n / valid_generator.batch_size), \n",
    "            callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
